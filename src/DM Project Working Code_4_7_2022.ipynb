{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "68dfa90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1269065755179524096</td>\n",
       "      <td>2020-06-06 00:37:08+00:00</td>\n",
       "      <td>weâ€™ve seen the power that our voices have wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268940899616243715</td>\n",
       "      <td>2020-06-05 16:21:00+00:00</td>\n",
       "      <td>i heard betty reid soskin is retiring at 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1268940899616243715</td>\n",
       "      <td>2020-06-05 16:21:00+00:00</td>\n",
       "      <td>on national gun violence awareness day, we #we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1268682939799425024</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>i'm proud of titus, ashton, thaddeus, jalen, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1268682939799425024</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>third, every city in this country should be a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 created_at  \\\n",
       "0  1269065755179524096  2020-06-06 00:37:08+00:00   \n",
       "1  1268940899616243715  2020-06-05 16:21:00+00:00   \n",
       "2  1268940899616243715  2020-06-05 16:21:00+00:00   \n",
       "3  1268682939799425024  2020-06-04 23:15:58+00:00   \n",
       "4  1268682939799425024  2020-06-04 23:15:58+00:00   \n",
       "\n",
       "                                                text  \n",
       "0  weâ€™ve seen the power that our voices have wh...  \n",
       "1  i heard betty reid soskin is retiring at 100, ...  \n",
       "2  on national gun violence awareness day, we #we...  \n",
       "3  i'm proud of titus, ashton, thaddeus, jalen, m...  \n",
       "4  third, every city in this country should be a ...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the first set of data from Arts and Painting category\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\Dell\\\\Data Mining Project\\\\dataset\\\\tweets_barackObama.csv')\n",
    "# df.drop(['Unnamed: 0', 'Index',  \n",
    "#                 'Location', 'Subcategory',\n",
    "#        'Unnamed: 5'], axis=1, inplace=True)\n",
    "df['text'] = df['text'].str.lower()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4e32acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#artgallery, \\n#artnews,\\n#artinfo,\\n#painting,\\n#photo,\\n#openaccessarticle,\\n#openscience,\\n#access,\\n#issue,\\n#journals,\\n#papers,\\n#scienceopen, \\n#photography,  \\n#abstract,\\n#acrylic, \\n#watercolor,\\n#music,\\n#video,\\n#musiclove,\\n#newmusic,\\n#nowplaying,\\n#radio,\\n#live,\\n#apple,\\n#life,\\n#hiphop,\\n#artist,\\n#musicartist,\\n#rock,\\n#music,\\n#musician,\\n#musicians,\\n#musicproducer,\\n#musicvideo,\\n#musicman,\\n#musicismylife,\\n#musicianlife,\\n#musicmonday,\\n#musicstudio,\\n#soundcloud,\\n#podcast,\\n#spotify,\\n#applemusic,\\n#tidal,\\n#musicstreaming,\\n#itunes,\\n#AmWriting,\\n#WritersLife,\\n#WriterWednesday,\\n#WriteTip,\\n#WordCount,\\n#FollowFriday,\\n#FridayReads,\\n#WritingPrompt,\\n#BookGiveaway,\\n#TuesdayMotivation, \\n#CharityTuesday,\\n#TravelTuesday,\\n#TuesdayThoughts,\\n#SampleSunday,\\n#meme,\\n#usa,\\n#freedom,\\n#america,\\n#open,\\n#openness,\\n#argentina,\\n#news,\\n#power,\\n#blacklivesmatter,\\n#trump,\\n#covid,\\n#feminism'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Openness dictionary - arts, painting, music, creative, imaginative, \n",
    "\n",
    "openness_dict = '''#artgallery, #artnews,\n",
    "#artinfo,\n",
    "#painting,\n",
    "#photo,\n",
    "#openaccessarticle,\n",
    "#openscience,\n",
    "#access,\n",
    "#issue,\n",
    "#journals,\n",
    "#papers,\n",
    "#scienceopen, \n",
    "#photography,  \n",
    "#abstract,\n",
    "#acrylic, \n",
    "#watercolor,\n",
    "#music,\n",
    "#video,\n",
    "#musiclove,\n",
    "#newmusic,\n",
    "#nowplaying,\n",
    "#radio,\n",
    "#live,\n",
    "#apple,\n",
    "#life,\n",
    "#hiphop,\n",
    "#artist,\n",
    "#musicartist,\n",
    "#rock,\n",
    "#music,\n",
    "#musician,\n",
    "#musicians,\n",
    "#musicproducer,\n",
    "#musicvideo,\n",
    "#musicman,\n",
    "#musicismylife,\n",
    "#musicianlife,\n",
    "#musicmonday,\n",
    "#musicstudio,\n",
    "#soundcloud,\n",
    "#podcast,\n",
    "#spotify,\n",
    "#applemusic,\n",
    "#tidal,\n",
    "#musicstreaming,\n",
    "#itunes,\n",
    "#AmWriting,\n",
    "#WritersLife,\n",
    "#WriterWednesday,\n",
    "#WriteTip,\n",
    "#WordCount,\n",
    "#FollowFriday,\n",
    "#FridayReads,\n",
    "#WritingPrompt,\n",
    "#BookGiveaway,\n",
    "#TuesdayMotivation, \n",
    "#CharityTuesday,\n",
    "#TravelTuesday,\n",
    "#TuesdayThoughts,\n",
    "#SampleSunday,\n",
    "#meme,\n",
    "#usa,\n",
    "#freedom,\n",
    "#america,\n",
    "#open,\n",
    "#openness,\n",
    "#argentina,\n",
    "#news,\n",
    "#power,\n",
    "#blacklivesmatter,\n",
    "#trump,\n",
    "#covid,\n",
    "#feminism'''\n",
    "# openness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ac9e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agreeableness dictionary\n",
    "\n",
    "agree_dict = '''\n",
    "#weekend,\n",
    "#sunday,\n",
    "#youtube,\n",
    "#film,\n",
    "#comedy,\n",
    "#sports,\n",
    "#starwars,\n",
    "#apple,\n",
    "#joy,\n",
    "#cover,\n",
    "#movies,\n",
    "#words,\n",
    "#spotify,\n",
    "#baseball,\n",
    "#podcast,\n",
    "#entertainment,\n",
    "#kindness,\n",
    "#mlb,\n",
    "#power,\n",
    "#speak,\n",
    "#google,\n",
    "#thinking,\n",
    "#agreeable,\n",
    "#localeconomy,\n",
    "#ethicalliving,\n",
    "#traceability,\n",
    "#sustainablelife,\n",
    "#familywork,\n",
    "#sociallyresponsible,\n",
    "#fairtradefortnight,\n",
    "#socialenterprise,\n",
    "#preciousplastic,\n",
    "#veggiehotels,\n",
    "#givingback,\n",
    "#community,\n",
    "#givingtuesday,\n",
    "#charity,\n",
    "#kids,\n",
    "#year,\n",
    "#charities,\n",
    "#love,\n",
    "#toy,\n",
    "#giving,\n",
    "#support,\n",
    "#time,\n",
    "#drive,\n",
    "#saturday,\n",
    "#holiday,\n",
    "#today,\n",
    "#christmas,\n",
    "#shop,\n",
    "#tuesday,\n",
    "#big,\n",
    "#tomorrow,\n",
    "#volunteering,\n",
    "#children,\n",
    "#life,\n",
    "#gratitude,\n",
    "#empathy,\n",
    "#sympathy,\n",
    "#thank\n",
    "'''\n",
    "# agree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d9fae5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openness_list = openness_dict.split(\",\")\n",
    "# openness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a0f949d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "open_cleaned = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in openness_list]\n",
    "# open_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f829e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove hashtags and special characters\n",
    "# re - regular expression\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_hashtags(str):\n",
    "    cleaned_dict = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",str)\n",
    "    return cleaned_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf4b5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "agree_list = agree_dict.split(\",\")\n",
    "# agree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ad8627a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "agree_cleaned = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in agree_list]\n",
    "# agree_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f071c89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weâ€™ve seen the power that our voices have wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i heard betty reid soskin is retiring at 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on national gun violence awareness day, we #we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'm proud of titus, ashton, thaddeus, jalen, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>third, every city in this country should be a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  weâ€™ve seen the power that our voices have wh...\n",
       "1  i heard betty reid soskin is retiring at 100, ...\n",
       "2  on national gun violence awareness day, we #we...\n",
       "3  i'm proud of titus, ashton, thaddeus, jalen, m...\n",
       "4  third, every city in this country should be a ..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = df[[\"text\"]]\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c4c14f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "# print(stopwords.words('english'))\n",
    "\n",
    "df_tweets = df[\"text\"]\n",
    "word_token_list = []\n",
    "filtered_tweet = []\n",
    "\n",
    "for i in range(len(df_tweets.index)):\n",
    "    word_token = word_tokenize(df_tweets[i])\n",
    "    word_token_list.append(word_token)\n",
    "    \n",
    "# word_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3668ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[weâ€™ve, seen, the, power, that, our, voices,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, heard, betty, reid, soskin, is, retiring, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[on, national, gun, violence, awareness, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, 'm, proud, of, titus, ,, ashton, ,, thadde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[third, ,, every, city, in, this, country, sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tokenized_tweets\n",
       "0  [weâ€™ve, seen, the, power, that, our, voices,...\n",
       "1  [i, heard, betty, reid, soskin, is, retiring, ...\n",
       "2  [on, national, gun, violence, awareness, day, ...\n",
       "3  [i, 'm, proud, of, titus, ,, ashton, ,, thadde...\n",
       "4  [third, ,, every, city, in, this, country, sho..."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(word_token_list)\n",
    "df1['tokenized_tweets']=df1.apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "df_token = df1[['tokenized_tweets']]\n",
    "df_token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "66f05dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1269065755179524096</td>\n",
       "      <td>2020-06-06 00:37:08+00:00</td>\n",
       "      <td>weâ€™ve seen the power that our voices have wh...</td>\n",
       "      <td>[weâ€™ve, seen, the, power, that, our, voices,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268940899616243715</td>\n",
       "      <td>2020-06-05 16:21:00+00:00</td>\n",
       "      <td>i heard betty reid soskin is retiring at 100, ...</td>\n",
       "      <td>[i, heard, betty, reid, soskin, is, retiring, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1268940899616243715</td>\n",
       "      <td>2020-06-05 16:21:00+00:00</td>\n",
       "      <td>on national gun violence awareness day, we #we...</td>\n",
       "      <td>[on, national, gun, violence, awareness, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1268682939799425024</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>i'm proud of titus, ashton, thaddeus, jalen, m...</td>\n",
       "      <td>[i, 'm, proud, of, titus, ,, ashton, ,, thadde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1268682939799425024</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>third, every city in this country should be a ...</td>\n",
       "      <td>[third, ,, every, city, in, this, country, sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 created_at  \\\n",
       "0  1269065755179524096  2020-06-06 00:37:08+00:00   \n",
       "1  1268940899616243715  2020-06-05 16:21:00+00:00   \n",
       "2  1268940899616243715  2020-06-05 16:21:00+00:00   \n",
       "3  1268682939799425024  2020-06-04 23:15:58+00:00   \n",
       "4  1268682939799425024  2020-06-04 23:15:58+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  weâ€™ve seen the power that our voices have wh...   \n",
       "1  i heard betty reid soskin is retiring at 100, ...   \n",
       "2  on national gun violence awareness day, we #we...   \n",
       "3  i'm proud of titus, ashton, thaddeus, jalen, m...   \n",
       "4  third, every city in this country should be a ...   \n",
       "\n",
       "                                    tokenized_tweets  \n",
       "0  [weâ€™ve, seen, the, power, that, our, voices,...  \n",
       "1  [i, heard, betty, reid, soskin, is, retiring, ...  \n",
       "2  [on, national, gun, violence, awareness, day, ...  \n",
       "3  [i, 'm, proud, of, titus, ,, ashton, ,, thadde...  \n",
       "4  [third, ,, every, city, in, this, country, sho...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = pd.concat([df.reset_index(drop=True), df_token], axis=1)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae46cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weâ€™ve', 'seen', 'the', 'power', 'that', 'our', 'voices', 'have', 'when', 'we', 'speak', 'out', 'about', 'injusticeâ€', '“', 'â€', '“', 'but', 'we', 'also', 'know', 'the', 'toll', 'that', 'it', 'takeâ€¦', 'https', ':', '//t.co/obdm8rkgef']\n",
      "29\n",
      "yes, present in openness dict\n",
      "yes, present in agreeableness dict\n",
      "yes, present in agreeableness dict\n",
      "['i', 'heard', 'betty', 'reid', 'soskin', 'is', 'retiring', 'at', '100', ',', 'and', 'want', 'to', 'congratulate', 'her', 'for', 'more', 'than', 'a', 'decade', 'of', 'service', 'as', 'a', 'nâ€¦', 'https', ':', '//t.co/upyzks8jri']\n",
      "28\n",
      "['on', 'national', 'gun', 'violence', 'awareness', 'day', ',', 'we', '#', 'wearorange', 'to', 'honor', 'the', 'victims', 'and', 'survivors', 'of', 'gun', 'violenceâ€', '“', 'â€', '“', 'which', 'coâ€¦', 'https', ':', '//t.co/cnv3oq1knd']\n",
      "27\n",
      "['i', \"'m\", 'proud', 'of', 'titus', ',', 'ashton', ',', 'thaddeus', ',', 'jalen', ',', 'mckinley', 'and', 'peter', 'for', 'representing', '@', 'mbk_alliance', 'at', '@', 'marchmadnessmbb.â€¦', 'https', ':', '//t.co/57h6xda0jp']\n",
      "25\n",
      "['third', ',', 'every', 'city', 'in', 'this', 'country', 'should', 'be', 'a', '@', 'mbk_alliance', 'community', '.', 'we', 'have', '250', 'cities', ',', 'counties', ',', 'and', 'tribal', 'natâ€¦', 'https', ':', '//t.co/eltgdznozd']\n",
      "27\n",
      "yes, present in agreeableness dict\n",
      "['today', '@', 'potus', 'announced', 'that', 'the', 'u.s.', 'will', 'be', 'welcoming', '100,000', 'refugees', 'fleeing', 'the', 'war', 'in', 'ukraine', '.', 'â', 'this', 'is', 'the', 'râ€¦', 'https', ':', '//t.co/wlyzascr4i']\n",
      "26\n",
      "yes, present in agreeableness dict\n",
      "['second', ',', 'every', 'mayor', 'should', 'review', 'their', 'use', 'of', 'force', 'policies', 'with', 'members', 'of', 'their', 'community', 'and', 'commit', 'to', 'reportâ€¦', 'https', ':', '//t.co/22stcond3e']\n",
      "23\n",
      "yes, present in agreeableness dict\n",
      "['as', 'the', 'first', 'woman', 'to', 'serve', 'as', 'americaâ€™s', 'top', 'diplomat', ',', 'madeleine', 'albright', 'was', 'a', 'champion', 'for', 'democratic', 'values', '.', 'micâ€¦', 'https', ':', '//t.co/fpuafrq0ry']\n",
      "24\n",
      "['first', ',', 'there', 'are', 'specific', 'evidence-based', 'reforms', 'that', 'would', 'build', 'trust', ',', 'save', 'lives', ',', 'and', 'lead', 'to', 'a', 'decrease', 'in', 'crimâ€¦', 'https', ':', '//t.co/y9nyl1amep']\n",
      "25\n",
      "['the', 'other', 'day', ',', 'i', 'called', 'up', 'donnamarie', ',', 'steve', ',', 'and', 'amy', 'to', 'hear', 'how', 'the', 'affordable', 'care', 'act', 'changed', 'their', 'lives', 'and', 'tâ€¦', 'https', ':', '//t.co/abfpqgc90e']\n",
      "28\n",
      "['real', 'change', 'requires', 'protest', 'to', 'highlight', 'a', 'problem', ',', 'and', 'politics', 'to', 'implement', 'practical', 'solutions', 'and', 'laws', '.', 'as', 'i', 'mâ€¦', 'https', ':', '//t.co/yg1ta1ky1n']\n",
      "24\n",
      "['rt', '@', 'potus', ':', 'twelve', 'years', 'ago', ',', 'i', 'proudly', 'stood', 'beside', 'president', '@', 'barackobama', 'as', 'he', 'signed', 'into', 'law', 'the', 'most', 'consequential', 'expansion', 'of', 'healthâ€¦']\n",
      "26\n",
      "['in', 'our', '@', 'mbk_alliance', 'town', 'hall', 'yesterday', ',', 'i', 'mentioned', 'james', 'baldwin', \"'s\", 'the', 'fire', 'next', 'time', '.', 'from', '1962', ',', 'it', 'remains', 'a', 'sâ€¦', 'https', ':', '//t.co/ywcjoxebu3']\n",
      "28\n",
      "yes, present in agreeableness dict\n",
      "['.', '@', 'potusâ€™s', 'american', 'rescue', 'plan', 'helped', 'strengthen', 'the', 'affordable', 'care', 'act', 'by', 'lowering', 'costs', 'and', 'encouraging', 'a', 'recordâ€¦', 'https', ':', '//t.co/i9rf1p0dl0']\n",
      "22\n",
      "['and', 'third', ',', 'an', 'extraordinary', 'essay', 'by', 'the', 'former', 'chairman', 'of', 'the', 'joint', 'chiefs', 'of', 'staff', 'of', 'the', 'u.s.', 'armed', 'forces', ',', 'mikâ€¦', 'https', ':', '//t.co/jcbgwikaaq']\n",
      "26\n",
      "['during', 'the', 'pandemic', ',', 'the', 'affordable', 'care', 'act', 'helped', 'make', 'vaccines', 'and', 'covid-19', 'tests', 'available', 'for', 'free', ',', 'covered', 'emâ€¦', 'https', ':', '//t.co/quzhfxhuct']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_personality_score(df,a):\n",
    "    \n",
    "    max_list = []\n",
    "    persona_list = []\n",
    "    open_count, agree_count = 0 , 0\n",
    "    open_ratio, agree_ratio = 0 , 0\n",
    "    \n",
    "    for i in range(len(df.index)):\n",
    "        print(df[a][i])\n",
    "        print(len(df[a][i]))\n",
    "        max_score = 0\n",
    "        open_count, agree_count = 0 , 0\n",
    "        open_ratio, agree_ratio = 0 , 0\n",
    "        \n",
    "        for j in range(len(df[a][i])):\n",
    "            \n",
    "            if (df[a][i][j] in open_cleaned):\n",
    "                open_count += 1\n",
    "                open_ratio = open_count/len(open_cleaned)\n",
    "                print(\"yes, present in openness dict\")\n",
    "            if (df[a][i][j] in agree_cleaned):\n",
    "                agree_count +=1\n",
    "                agree_ratio = agree_count/len(agree_cleaned)\n",
    "                print(\"yes, present in agreeableness dict\")\n",
    "            \n",
    "        max_score = max(open_ratio,agree_ratio)\n",
    "        max_list.append(max_score)\n",
    "        \n",
    "        if max_score == 0:\n",
    "            x = \"Unknown\"\n",
    "        elif max_score == open_ratio:\n",
    "            x = \"Openness\"\n",
    "        elif max_score == agree_ratio:\n",
    "            x = \"Agreeableness\"\n",
    "            \n",
    "        persona_list.append(x)\n",
    "            \n",
    "            \n",
    "    return max_list,persona_list\n",
    "\n",
    "\n",
    "df_cleaned[\"personality_score\"],df_cleaned[\"Personality\"] = get_personality_score(df_cleaned,\"tokenized_tweets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9ca7eaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>personality_score</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1269065755179524096</td>\n",
       "      <td>2020-06-06 00:37:08+00:00</td>\n",
       "      <td>weâ€™ve seen the power that our voices have wh...</td>\n",
       "      <td>[weâ€™ve, seen, the, power, that, our, voices,...</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>Agreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268940899616243715</td>\n",
       "      <td>2020-06-05 16:21:00+00:00</td>\n",
       "      <td>i heard betty reid soskin is retiring at 100, ...</td>\n",
       "      <td>[i, heard, betty, reid, soskin, is, retiring, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1268940899616243715</td>\n",
       "      <td>2020-06-05 16:21:00+00:00</td>\n",
       "      <td>on national gun violence awareness day, we #we...</td>\n",
       "      <td>[on, national, gun, violence, awareness, day, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1268682939799425024</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>i'm proud of titus, ashton, thaddeus, jalen, m...</td>\n",
       "      <td>[i, 'm, proud, of, titus, ,, ashton, ,, thadde...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1268682939799425024</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>third, every city in this country should be a ...</td>\n",
       "      <td>[third, ,, every, city, in, this, country, sho...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1268682938251710464</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>today @potus announced that the u.s. will be w...</td>\n",
       "      <td>[today, @, potus, announced, that, the, u.s., ...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1268682938251710464</td>\n",
       "      <td>2020-06-04 23:15:58+00:00</td>\n",
       "      <td>second, every mayor should review their use of...</td>\n",
       "      <td>[second, ,, every, mayor, should, review, thei...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1268682936968241157</td>\n",
       "      <td>2020-06-04 23:15:57+00:00</td>\n",
       "      <td>as the first woman to serve as americaâ€™s top...</td>\n",
       "      <td>[as, the, first, woman, to, serve, as, america...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1268682936968241157</td>\n",
       "      <td>2020-06-04 23:15:57+00:00</td>\n",
       "      <td>first, there are specific evidence-based refor...</td>\n",
       "      <td>[first, ,, there, are, specific, evidence-base...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1268682936221609994</td>\n",
       "      <td>2020-06-04 23:15:57+00:00</td>\n",
       "      <td>the other day, i called up donnamarie, steve, ...</td>\n",
       "      <td>[the, other, day, ,, i, called, up, donnamarie...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1506690376471621634</td>\n",
       "      <td>2020-06-04 23:15:57+00:00</td>\n",
       "      <td>real change requires protest to highlight a pr...</td>\n",
       "      <td>[real, change, requires, protest, to, highligh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1268529169702543360</td>\n",
       "      <td>2020-06-04 13:04:56+00:00</td>\n",
       "      <td>rt @potus: twelve years ago, i proudly stood b...</td>\n",
       "      <td>[rt, @, potus, :, twelve, years, ago, ,, i, pr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1268529169702543360</td>\n",
       "      <td>2020-06-04 13:04:56+00:00</td>\n",
       "      <td>in our @mbk_alliance town hall yesterday, i me...</td>\n",
       "      <td>[in, our, @, mbk_alliance, town, hall, yesterd...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1268196828140503042</td>\n",
       "      <td>2020-06-03 15:04:20+00:00</td>\n",
       "      <td>.@potusâ€™s american rescue plan helped streng...</td>\n",
       "      <td>[., @, potusâ€™s, american, rescue, plan, help...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1506662260588089357</td>\n",
       "      <td>2020-06-03 15:04:20+00:00</td>\n",
       "      <td>and third, an extraordinary essay by the forme...</td>\n",
       "      <td>[and, third, ,, an, extraordinary, essay, by, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1506662260588089357</td>\n",
       "      <td>2022-03-23 16:00:50+00:00</td>\n",
       "      <td>during the pandemic, the affordable care act h...</td>\n",
       "      <td>[during, the, pandemic, ,, the, affordable, ca...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                 created_at  \\\n",
       "0   1269065755179524096  2020-06-06 00:37:08+00:00   \n",
       "1   1268940899616243715  2020-06-05 16:21:00+00:00   \n",
       "2   1268940899616243715  2020-06-05 16:21:00+00:00   \n",
       "3   1268682939799425024  2020-06-04 23:15:58+00:00   \n",
       "4   1268682939799425024  2020-06-04 23:15:58+00:00   \n",
       "5   1268682938251710464  2020-06-04 23:15:58+00:00   \n",
       "6   1268682938251710464  2020-06-04 23:15:58+00:00   \n",
       "7   1268682936968241157  2020-06-04 23:15:57+00:00   \n",
       "8   1268682936968241157  2020-06-04 23:15:57+00:00   \n",
       "9   1268682936221609994  2020-06-04 23:15:57+00:00   \n",
       "10  1506690376471621634  2020-06-04 23:15:57+00:00   \n",
       "11  1268529169702543360  2020-06-04 13:04:56+00:00   \n",
       "12  1268529169702543360  2020-06-04 13:04:56+00:00   \n",
       "13  1268196828140503042  2020-06-03 15:04:20+00:00   \n",
       "14  1506662260588089357  2020-06-03 15:04:20+00:00   \n",
       "15  1506662260588089357  2022-03-23 16:00:50+00:00   \n",
       "\n",
       "                                                 text  \\\n",
       "0   weâ€™ve seen the power that our voices have wh...   \n",
       "1   i heard betty reid soskin is retiring at 100, ...   \n",
       "2   on national gun violence awareness day, we #we...   \n",
       "3   i'm proud of titus, ashton, thaddeus, jalen, m...   \n",
       "4   third, every city in this country should be a ...   \n",
       "5   today @potus announced that the u.s. will be w...   \n",
       "6   second, every mayor should review their use of...   \n",
       "7   as the first woman to serve as americaâ€™s top...   \n",
       "8   first, there are specific evidence-based refor...   \n",
       "9   the other day, i called up donnamarie, steve, ...   \n",
       "10  real change requires protest to highlight a pr...   \n",
       "11  rt @potus: twelve years ago, i proudly stood b...   \n",
       "12  in our @mbk_alliance town hall yesterday, i me...   \n",
       "13  .@potusâ€™s american rescue plan helped streng...   \n",
       "14  and third, an extraordinary essay by the forme...   \n",
       "15  during the pandemic, the affordable care act h...   \n",
       "\n",
       "                                     tokenized_tweets  personality_score  \\\n",
       "0   [weâ€™ve, seen, the, power, that, our, voices,...           0.032787   \n",
       "1   [i, heard, betty, reid, soskin, is, retiring, ...           0.000000   \n",
       "2   [on, national, gun, violence, awareness, day, ...           0.000000   \n",
       "3   [i, 'm, proud, of, titus, ,, ashton, ,, thadde...           0.000000   \n",
       "4   [third, ,, every, city, in, this, country, sho...           0.016393   \n",
       "5   [today, @, potus, announced, that, the, u.s., ...           0.016393   \n",
       "6   [second, ,, every, mayor, should, review, thei...           0.016393   \n",
       "7   [as, the, first, woman, to, serve, as, america...           0.000000   \n",
       "8   [first, ,, there, are, specific, evidence-base...           0.000000   \n",
       "9   [the, other, day, ,, i, called, up, donnamarie...           0.000000   \n",
       "10  [real, change, requires, protest, to, highligh...           0.000000   \n",
       "11  [rt, @, potus, :, twelve, years, ago, ,, i, pr...           0.000000   \n",
       "12  [in, our, @, mbk_alliance, town, hall, yesterd...           0.016393   \n",
       "13  [., @, potusâ€™s, american, rescue, plan, help...           0.000000   \n",
       "14  [and, third, ,, an, extraordinary, essay, by, ...           0.000000   \n",
       "15  [during, the, pandemic, ,, the, affordable, ca...           0.000000   \n",
       "\n",
       "      Personality  \n",
       "0   Agreeableness  \n",
       "1         Unknown  \n",
       "2         Unknown  \n",
       "3         Unknown  \n",
       "4   Agreeableness  \n",
       "5   Agreeableness  \n",
       "6   Agreeableness  \n",
       "7         Unknown  \n",
       "8         Unknown  \n",
       "9         Unknown  \n",
       "10        Unknown  \n",
       "11        Unknown  \n",
       "12  Agreeableness  \n",
       "13        Unknown  \n",
       "14        Unknown  \n",
       "15        Unknown  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
