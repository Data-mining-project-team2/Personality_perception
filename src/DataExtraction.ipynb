{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f50346dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for just one user\n",
    "import re\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "consumer_key = \"nZ5pbaBEdbqxRnyAtTwQw5fYz\"\n",
    "consumer_secret = \"RiFL5Shi4UMwrZvWQAkUqOJ29WD0WVnVsQIkDWE5El4n918BV0\"\n",
    "access_token = \"1499277053031432193-hGvED3N6PyevECoB8xhSo2Rxn7unTB\"\n",
    "access_token_secret = \"daL2guXD4xcm3dy1g5rIlaymBdmQ25gyxjEXN1PKuTmNg\"\n",
    "\n",
    "\n",
    "def twitter_setup():\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "    return api\n",
    "\n",
    "extractor = twitter_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e9eb49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetBO = extractor.user_timeline(screen_name=\"imVkohli\", count=200,tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5ac0a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1385853592574119935\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1297779414780923903\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 1199910806722211840\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 1155381370757107712\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 1053175566071869439\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 942985622142070784\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 894466905490280447\n",
      "...1600 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Return API with authentication:\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "alltweets = []  \n",
    "new_tweets = api.user_timeline(screen_name = \"imVkohli\",count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "oldest = alltweets[-1].id - 1\n",
    "    \n",
    "#keep grabbing tweets until there are no tweets left to grab\n",
    "for i in range(1,8):\n",
    "    print(f\"getting tweets before {oldest}\")\n",
    "\n",
    "    #all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name = \"imVkohli\",count=200,max_id=oldest)\n",
    "\n",
    "    #save most recent tweetsz\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #update the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "#transform the tweepy tweets into a 2D array that will populate the csv \n",
    "outtweets = [[\"Virat Kohli\", tweet.text] for tweet in alltweets]\n",
    "\n",
    " \n",
    "#write the csv  \n",
    "with open(f'new_{\"imVkohli\"}_tweets.csv', 'w', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\",\"text\"])\n",
    "    writer.writerows(outtweets)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7bbee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetBO = extractor.user_timeline(screen_name=\"joliestweet\", count=200,tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f9f236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1461792024890331137\n",
      "...398 tweets downloaded so far\n",
      "getting tweets before 1452338639862734862\n",
      "...597 tweets downloaded so far\n",
      "getting tweets before 1443778985108901889\n",
      "...777 tweets downloaded so far\n",
      "getting tweets before 1413235331353153536\n",
      "...958 tweets downloaded so far\n",
      "getting tweets before 1379440346371866624\n",
      "...1133 tweets downloaded so far\n",
      "getting tweets before 1314659788165390339\n",
      "...1284 tweets downloaded so far\n",
      "getting tweets before 1273776118932426752\n",
      "...1453 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Return API with authentication:\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "alltweets = []  \n",
    "new_tweets = api.user_timeline(screen_name = \"joliestweet\",count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "oldest = alltweets[-1].id - 1\n",
    "    \n",
    "#keep grabbing tweets until there are no tweets left to grab\n",
    "for i in range(1,8):\n",
    "    print(f\"getting tweets before {oldest}\")\n",
    "\n",
    "    #all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name = \"joliestweet\",count=200,max_id=oldest)\n",
    "\n",
    "    #save most recent tweetsz\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #update the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "#transform the tweepy tweets into a 2D array that will populate the csv \n",
    "outtweets = [[\"joliestweet\", tweet.text] for tweet in alltweets]\n",
    "\n",
    " \n",
    "#write the csv  \n",
    "with open(f'new_{\"joliestweet\"}_tweets.csv', 'w', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\",\"text\"])\n",
    "    writer.writerows(outtweets)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3d90f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetBO = extractor.user_timeline(screen_name=\"kanyewest\", count=600,tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "193d5cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1308384830237806592\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1306216921545621503\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 1292306760397721601\n",
      "...787 tweets downloaded so far\n",
      "getting tweets before 1080201232537419777\n",
      "...966 tweets downloaded so far\n",
      "getting tweets before 1073418802380111871\n",
      "...1155 tweets downloaded so far\n",
      "getting tweets before 1057354881546272768\n",
      "...1347 tweets downloaded so far\n",
      "getting tweets before 1045061267541508095\n",
      "...1547 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "#rerun some functions and make them global\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Return API with authentication:\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "alltweets = []  \n",
    "new_tweets = api.user_timeline(screen_name = \"kanyewest\",count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "oldest = alltweets[-1].id - 1\n",
    "    \n",
    "#keep grabbing tweets until there are no tweets left to grab\n",
    "for i in range(1,8):\n",
    "    print(f\"getting tweets before {oldest}\")\n",
    "\n",
    "    #all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name = \"kanyewest\",count=200,max_id=oldest)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #update the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "#transform the tweepy tweets into a 2D array that will populate the csv \n",
    "outtweets = [[\"Kanye West\" , tweet.text] for tweet in alltweets]\n",
    "\n",
    "#write the csv  \n",
    "#write the csv  \n",
    "with open(f'new_{\"Kanyewest\"}_tweets.csv', 'w', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\",\"text\"])\n",
    "    writer.writerows(outtweets)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c18e422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetBO = extractor.user_timeline(screen_name=\"BarackObama\", count=600,tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a002eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1427639234576490505\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1337140440169123845\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 1274021940760641535\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 1156618530814603265\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 929366549009502207\n",
      "...1200 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "#rerun some functions and make them global\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Return API with authentication:\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "alltweets = []  \n",
    "new_tweets = api.user_timeline(screen_name = \"BarackObama\",count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "oldest = alltweets[-1].id - 1\n",
    "    \n",
    "#keep grabbing tweets until there are no tweets left to grab\n",
    "for i in range(1,6):\n",
    "    print(f\"getting tweets before {oldest}\")\n",
    "\n",
    "    #all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name = \"BarackObama\",count=200,max_id=oldest)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #update the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "#transform the tweepy tweets into a 2D array that will populate the csv \n",
    "outtweets = [[\"Barack Obama\" , tweet.text] for tweet in alltweets]\n",
    "\n",
    "#write the csv  \n",
    "#write the csv  \n",
    "with open(f'new_{\"BarackObama\"}_tweets.csv', 'w', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\",\"text\"])\n",
    "    writer.writerows(outtweets)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "81136d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5800, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet1=\"C:\\\\Users\\\\mahin\\\\Personality_perception\\\\src\\\\new_imVkohli_tweets.csv\"\n",
    "tweet2=\"C:\\\\Users\\\\mahin\\\\Personality_perception\\\\src\\\\new_BarackObama_tweets.csv\"\n",
    "tweet3=\"C:\\\\Users\\\\mahin\\\\Personality_perception\\\\src\\\\new_Kanyewest_tweets.csv\"\n",
    "tweet4=\"C:\\\\Users\\\\mahin\\\\Personality_perception\\\\src\\\\new_joliestweet_tweets.csv\"\n",
    "\n",
    "dataFrame = pd.concat(\n",
    "   map(pd.read_csv, [tweet1,tweet2,tweet3,tweet4]), ignore_index=True)\n",
    "\n",
    "dataFrame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "281a82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.to_csv(r'C:\\\\Users\\\\mahin\\\\Personality_perception\\\\src\\\\twitter_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5028af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
