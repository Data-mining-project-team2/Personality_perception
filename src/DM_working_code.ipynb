{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6908d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Required Libraries\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "stopwords_english = stopwords.words('english')\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dbaba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Dataframe cell \n",
    "\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\vinu1\\\\Personality_perception\\\\data\\\\Tweets\\\\twitter_data.csv')\n",
    "# df.drop(['Unnamed: 0', 'Index',  \n",
    "#                 'Location', 'Subcategory',\n",
    "#        'Unnamed: 5'], axis=1, inplace=True)\n",
    "# df['text'] = df['text'].str.lower()\n",
    "# df['text']\n",
    "\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "train_pos = all_positive_tweets[:]\n",
    "train_neg = all_negative_tweets[:]\n",
    "train_x = train_pos+train_neg\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "df_train = pd.DataFrame()\n",
    "df_train[\"text\"] = train_x\n",
    "df_train[\"sentiment\"] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d9a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    \n",
    "    def __init__(self, df_test,df_train):\n",
    "         self.df_test_cleaned = df_test\n",
    "         self.df_train_cleaned = df_train\n",
    "         self.Openness_list = []\n",
    "         self.Agreeableness_list = []\n",
    "         self.all_positive_tweets = []\n",
    "         self.all_negative_tweets = []\n",
    "         self.stopwords_english = stopwords.words('english')\n",
    "        \n",
    "    def read_persona_dict(self, Personality):\n",
    "        for i in Personality:\n",
    "            path = f\"C:\\\\Users\\\\vinu1\\\\Personality_perception\\\\data\\\\Dictionary\\\\{i}.txt\"\n",
    "            with open(path) as file:\n",
    "                if i == \"Openness\":\n",
    "                   self.Openness_list = [line.rstrip() for line in file]\n",
    "                   self.Openness_list = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in self.Openness_list]\n",
    "                elif i == \"Agreeableness\":\n",
    "                   self.Agreeableness_list = [line.rstrip() for line in file]\n",
    "                   self.Agreeableness_list = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in self.Agreeableness_list]\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def pre_processing_dataframe(self,df):\n",
    "#         df[\"text\"] = df[\"text\"].str.lower()\n",
    "#         word_token_list = []\n",
    "#         for i in range(len(df.index)):\n",
    "#             word_token = word_tokenize(df[\"text\"][i])\n",
    "#             word_token_list.append(word_token)\n",
    "#         df1 = pd.DataFrame(word_token_list)\n",
    "#         df1['tokenized_tweets']=df1.apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "#         df_token = df1[['tokenized_tweets']]\n",
    "#         df = pd.concat([df.reset_index(drop=True), df_token], axis=1)\n",
    "        \n",
    "        stopwords_english = stopwords.words('english')\n",
    "        punctuations = string.punctuation\n",
    "        stemmer = PorterStemmer()\n",
    "        #### Removing the unwanted things in the tweets\n",
    "        df[\"text\"]=df[\"text\"].apply(lambda x: re.sub(r'RT[\\s]+','', str(x)))\n",
    "        df['text']=df['text'].apply(lambda x: re.sub(r\"http\\S+\",'', str(x)))\n",
    "        df['text']=df['text'].apply(lambda x: re.sub(r'#', '', str(x)))\n",
    "        df['tokenized_tweets']=df['text'].apply(lambda x: word_tokenize(x))\n",
    "        \n",
    "        df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [word.lower() for word in x if (word not in stopwords_english and word not in punctuations)])\n",
    "\n",
    "\n",
    "        \n",
    "    def pre_process(self, x):\n",
    "        if x == \"train\":\n",
    "            self.pre_processing_dataframe(self.df_train_cleaned)\n",
    "        elif x == \"test\":\n",
    "            self.pre_processing_dataframe(self.df_test_cleaned)\n",
    "        \n",
    "    def get_persona_scores(self):\n",
    "        max_list = []\n",
    "        persona_list = []\n",
    "        open_count, agree_count = 0 , 0\n",
    "        open_ratio, agree_ratio = 0 , 0\n",
    "\n",
    "        for i in range(len(self.df_test_cleaned.index)):\n",
    "            max_score = 0\n",
    "            open_count, agree_count = 0 , 0\n",
    "            open_ratio, agree_ratio = 0 , 0\n",
    "            for j in range(len(self.df_test_cleaned[\"tokenized_tweets\"][i])):\n",
    "\n",
    "                if (self.df_test_cleaned[\"tokenized_tweets\"][i][j] in self.Openness_list):\n",
    "                    open_count += 1\n",
    "\n",
    "                    open_ratio = open_count/len(self.Openness_list)\n",
    "                if (self.df_test_cleaned[\"tokenized_tweets\"][i][j] in self.Agreeableness_list):\n",
    "                    agree_count +=1\n",
    "                    agree_ratio = agree_count/len(self.Agreeableness_list)\n",
    "            max_score = max(open_ratio,agree_ratio)\n",
    "            max_list.append(max_score)\n",
    "            \n",
    "\n",
    "            if max_score == 0:\n",
    "                x = \"Unknown\"\n",
    "            elif max_score == open_ratio:\n",
    "                x = \"Openness\"\n",
    "            elif max_score == agree_ratio:\n",
    "                x = \"Agreeableness\"\n",
    "\n",
    "            persona_list.append(x)\n",
    "\n",
    "\n",
    "        self.df_test_cleaned[\"personality_score\"] = max_list\n",
    "        self.df_test_cleaned[\"Personality\"] = persona_list\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e695cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_predict_data(CleanData):\n",
    "   def create_frequency(self):\n",
    "        freq_d = {}\n",
    "        for i in range(len(self.df_train_cleaned.index)):\n",
    "            for word in self.df_train_cleaned[\"tokenized_tweets\"][i]:\n",
    "                pair = (word, self.df_train_cleaned[\"sentiment\"][i])\n",
    "                if pair in freq_d:\n",
    "                    freq_d[pair] += 1\n",
    "                else:\n",
    "                    freq_d[pair] = freq_d.get(pair, 1)\n",
    "    \n",
    "        return freq_d\n",
    "    \n",
    "   def train_naive_bayes(self,freqs, train_x, train_y):\n",
    "        loglikelihood = {}\n",
    "        logprior = 0\n",
    "\n",
    "        unique_words = set([pair[0] for pair in freqs.keys()])\n",
    "\n",
    "        V = len(unique_words)\n",
    "\n",
    "        N_pos = N_neg = 0\n",
    "        for pair in freqs.keys():\n",
    "            if pair[1]>0:\n",
    "                N_pos+=freqs[(pair)]\n",
    "\n",
    "            else:\n",
    "                N_neg += freqs[(pair)]\n",
    "        D = train_y.shape[0]\n",
    "\n",
    "        D_pos = sum(train_y)\n",
    "\n",
    "        D_neg = D-sum(train_y)\n",
    "\n",
    "        logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "        for word in unique_words:\n",
    "            freq_pos = freqs.get((word, 1),0)\n",
    "            freq_neg = freqs.get((word, 0), 0)\n",
    "            p_w_pos = (freq_pos+1)/(N_pos+V)\n",
    "            p_w_neg = (freq_neg+1)/(N_neg+V)\n",
    "            loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "        return logprior, loglikelihood\n",
    "    \n",
    "   def naive_bayes_predict(self,logprior,loglikelihood):\n",
    "       sentiment_score = []\n",
    "       for i in range(len(self.df_test_cleaned.index)):\n",
    "               p = 0\n",
    "               p+=logprior\n",
    "               for word in self.df_test_cleaned[\"tokenized_tweets\"][i]:\n",
    "                 if word in loglikelihood:\n",
    "                   p+=loglikelihood[word]\n",
    "               sentiment_score.append(p)\n",
    "       self.df_test_cleaned[\"sentiment_score\"] = sentiment_score\n",
    "    \n",
    "   def sentiment_persona(self):\n",
    "      sentiment_persona = []\n",
    "      for i in range(len(self.df_test_cleaned.index)):\n",
    "                score  = self.df_test_cleaned[\"sentiment_score\"][i]\n",
    "                if (-0.5 < score < 0.5):\n",
    "                    x  = \"Neutral\"\n",
    "                elif (score < -0.5):\n",
    "                    x = \"Negative\"\n",
    "                elif (score > 0.5):\n",
    "                    x = \"Positive\"\n",
    "                sentiment_persona.append(x)\n",
    "      self.df_test_cleaned[\"sentiment_persona\"] = sentiment_persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "935f96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Personality = ['Openness', 'Agreeableness']\n",
    "# clean_data = CleanData(df)\n",
    "train_data = Training_predict_data(df_test, df_train)\n",
    "train_data.read_persona_dict(Personality)\n",
    "train_data.pre_process(\"test\")\n",
    "train_data.pre_process(\"train\")\n",
    "train_data.get_persona_scores()\n",
    "freq_d=train_data.create_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42683bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_data.train_naive_bayes(freq_d, train_x, train_y)\n",
    "\n",
    "train_data.naive_bayes_predict(logprior,loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df5f3026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>personality_score</th>\n",
       "      <th>Personality</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>The difference between a good attempt and a go...</td>\n",
       "      <td>[the, difference, good, attempt, good, catch, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.653895</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>I go from hot and uncomfortable to cool and re...</td>\n",
       "      <td>[i, go, hot, uncomfortable, cool, relaxed, tim...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>4.614811</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>Always a pleasure to see you paji. ‚≠êüêê\\r\\n@sach...</td>\n",
       "      <td>[always, pleasure, see, paji, ‚≠êüêê, sachin_rt]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.489529</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>Job done. ‚úåÔ∏è\\r\\n@RCBTweets</td>\n",
       "      <td>[job, done, ‚úåÔ∏è, rcbtweets]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.685999</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>Keep the grind on.</td>\n",
       "      <td>[keep, grind]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.914035</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>joliestweet</td>\n",
       "      <td>I AM READY, ANGIE!!</td>\n",
       "      <td>[i, am, ready, angie]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.162728</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>joliestweet</td>\n",
       "      <td>@ManaByte: The Eternals Trailer is Coming Soon...</td>\n",
       "      <td>[manabyte, the, eternals, trailer, coming, soon]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.268625</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>joliestweet</td>\n",
       "      <td>@Toastiewiththe: AngelinaJolie Angelina attend...</td>\n",
       "      <td>[toastiewiththe, angelinajolie, angelina, atte...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>2.130003</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>joliestweet</td>\n",
       "      <td>@ChronicComicsYT: This is by far the only thin...</td>\n",
       "      <td>[chroniccomicsyt, this, far, thing, i, 'm, tru...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.503399</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>joliestweet</td>\n",
       "      <td>@pnchhk: sexbomb on this planet</td>\n",
       "      <td>[pnchhk, sexbomb, planet]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.053797</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5800 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                               text  \\\n",
       "0     Virat Kohli  The difference between a good attempt and a go...   \n",
       "1     Virat Kohli  I go from hot and uncomfortable to cool and re...   \n",
       "2     Virat Kohli  Always a pleasure to see you paji. ‚≠êüêê\\r\\n@sach...   \n",
       "3     Virat Kohli                        Job done. ‚úåÔ∏è\\r\\n@RCBTweets    \n",
       "4     Virat Kohli                                Keep the grind on.    \n",
       "...           ...                                                ...   \n",
       "5795  joliestweet                               I AM READY, ANGIE!!    \n",
       "5796  joliestweet  @ManaByte: The Eternals Trailer is Coming Soon...   \n",
       "5797  joliestweet  @Toastiewiththe: AngelinaJolie Angelina attend...   \n",
       "5798  joliestweet  @ChronicComicsYT: This is by far the only thin...   \n",
       "5799  joliestweet                   @pnchhk: sexbomb on this planet    \n",
       "\n",
       "                                       tokenized_tweets  personality_score  \\\n",
       "0     [the, difference, good, attempt, good, catch, ...           0.000000   \n",
       "1     [i, go, hot, uncomfortable, cool, relaxed, tim...           0.016393   \n",
       "2          [always, pleasure, see, paji, ‚≠êüêê, sachin_rt]           0.000000   \n",
       "3                            [job, done, ‚úåÔ∏è, rcbtweets]           0.000000   \n",
       "4                                         [keep, grind]           0.000000   \n",
       "...                                                 ...                ...   \n",
       "5795                              [i, am, ready, angie]           0.000000   \n",
       "5796   [manabyte, the, eternals, trailer, coming, soon]           0.000000   \n",
       "5797  [toastiewiththe, angelinajolie, angelina, atte...           0.016393   \n",
       "5798  [chroniccomicsyt, this, far, thing, i, 'm, tru...           0.000000   \n",
       "5799                          [pnchhk, sexbomb, planet]           0.000000   \n",
       "\n",
       "        Personality  sentiment_score sentiment_persona  \n",
       "0           Unknown         2.653895          Positive  \n",
       "1     Agreeableness         4.614811          Positive  \n",
       "2           Unknown         2.489529          Positive  \n",
       "3           Unknown         1.685999          Positive  \n",
       "4           Unknown         0.914035          Positive  \n",
       "...             ...              ...               ...  \n",
       "5795        Unknown        -0.162728           Neutral  \n",
       "5796        Unknown        -0.268625           Neutral  \n",
       "5797  Agreeableness         2.130003          Positive  \n",
       "5798        Unknown         2.503399          Positive  \n",
       "5799        Unknown         1.053797          Positive  \n",
       "\n",
       "[5800 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sentiment_persona()\n",
    "train_data.df_test_cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
