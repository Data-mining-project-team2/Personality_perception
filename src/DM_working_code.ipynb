{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6908d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15876/214576717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'twitter_samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "## Required Libraries\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f139f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Dataframe cell \n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\vinu1\\\\Personality_perception\\\\data\\\\Tweets\\\\BarackObama_tweets.csv')\n",
    "# df.drop(['Unnamed: 0', 'Index',  \n",
    "#                 'Location', 'Subcategory',\n",
    "#        'Unnamed: 5'], axis=1, inplace=True)\n",
    "# df['text'] = df['text'].str.lower()\n",
    "# df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b2d9a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "         self.df_cleaned = df\n",
    "         self.Openness_list = []\n",
    "         self.Agreeableness_list = []\n",
    "         self.all_positive_tweets = []\n",
    "         self.all_negative_tweets = []\n",
    "         self.stopwords_english = stopwords.words('english')\n",
    "        \n",
    "    def read_persona_dict(self, Personality):\n",
    "        for i in Personality:\n",
    "            path = f\"C:\\\\Users\\\\vinu1\\\\Personality_perception\\\\data\\\\Dictionary\\\\{i}.txt\"\n",
    "            with open(path) as file:\n",
    "                if i == \"Openness\":\n",
    "                   self.Openness_list = [line.rstrip() for line in file]\n",
    "                   self.Openness_list = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in self.Openness_list]\n",
    "                elif i == \"Agreeableness\":\n",
    "                   self.Agreeableness_list = [line.rstrip() for line in file]\n",
    "                   self.Agreeableness_list = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in self.Agreeableness_list]\n",
    "\n",
    "    def pre_processing_dataframe(self):\n",
    "        self.df_cleaned[\"text\"] = self.df_cleaned[\"text\"].str.lower()\n",
    "        word_token_list = []\n",
    "        for i in range(len(self.df_cleaned.index)):\n",
    "            word_token = word_tokenize(self.df_cleaned[\"text\"][i])\n",
    "            word_token_list.append(word_token)\n",
    "        df1 = pd.DataFrame(word_token_list)\n",
    "        df1['tokenized_tweets']=df1.apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "        df_token = df1[['tokenized_tweets']]\n",
    "        self.df_cleaned = pd.concat([self.df_cleaned.reset_index(drop=True), df_token], axis=1)\n",
    "        \n",
    "    def get_persona_scores(self):\n",
    "        max_list = []\n",
    "        persona_list = []\n",
    "        open_count, agree_count = 0 , 0\n",
    "        open_ratio, agree_ratio = 0 , 0\n",
    "\n",
    "        for i in range(len(self.df_cleaned.index)):\n",
    "            max_score = 0\n",
    "            open_count, agree_count = 0 , 0\n",
    "            open_ratio, agree_ratio = 0 , 0\n",
    "\n",
    "            for j in range(len(self.df_cleaned[\"tokenized_tweets\"][i])):\n",
    "\n",
    "                if (self.df_cleaned[\"tokenized_tweets\"][i][j] in self.Openness_list):\n",
    "                    open_count += 1\n",
    "                    open_ratio = open_count/len(self.Openness_list)\n",
    "                if (self.df_cleaned[\"tokenized_tweets\"][i][j] in self.Agreeableness_list):\n",
    "                    agree_count +=1\n",
    "                    agree_ratio = agree_count/len(self.Agreeableness_list)\n",
    "\n",
    "            max_score = max(open_ratio,agree_ratio)\n",
    "            max_list.append(max_score)\n",
    "\n",
    "            if max_score == 0:\n",
    "                x = \"Unknown\"\n",
    "            elif max_score == open_ratio:\n",
    "                x = \"Openness\"\n",
    "            elif max_score == agree_ratio:\n",
    "                x = \"Agreeableness\"\n",
    "\n",
    "            persona_list.append(x)\n",
    "\n",
    "\n",
    "        self.df_cleaned[\"personality_score\"] = max_list\n",
    "        self.df_cleaned[\"Personality\"] = persona_list\n",
    "    \n",
    "    \n",
    "#     def get_twitter_sample(self):\n",
    "        \n",
    "#         punctuations = string.punctuation\n",
    "#         tokenizer = TweetTokenizer(preserve_case = False, strip_handles=True, reduce_len = True)\n",
    "#         stemmer = PorterStemmer()\n",
    "\n",
    "#         self.all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "#         self.all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "        \n",
    "        \n",
    "#         def remove_hyperlinks_marks_styles(tweet):\n",
    "#             new_tweet = re.sub(r'RT[\\s]+','', tweet)\n",
    "#             new_tweet = re.sub(r\"http\\S+\",'', new_tweet)\n",
    "#             new_tweet = re.sub(r'#', '',new_tweet)\n",
    "#             return new_tweet\n",
    "        \n",
    "        \n",
    "#         def tokenize_tweet(tweet):\n",
    "#             tweet_tokens = tokenizer.tokenize(tweet)\n",
    "#             return tweet_tokens\n",
    "\n",
    "        \n",
    "\n",
    "#         def remove_stopwords_punctuations(tweet_tokens):\n",
    "#             tweets_clean = []\n",
    "#             for word in tweet_tokens:\n",
    "#                if (word not in stopwords_english and word not in punctuations):\n",
    "#                        tweets_clean.append(word)\n",
    "#             return tweets_clean\n",
    "      \n",
    "#         def get_stem(tweets_clean):\n",
    "#             tweets_stem = []\n",
    "#             for word in tweets_clean:\n",
    "#                stem_word = stemmer.stem(word)\n",
    "#                tweets_stem.append(stem_word)\n",
    "#             return tweets_stem\n",
    "        \n",
    "    def get_sentiment_score():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bb48eecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>personality_score</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1510286021182771200</td>\n",
       "      <td>2022-04-02 16:00:21+00:00</td>\n",
       "      <td>i heard betty reid soskin is retiring at 100, ...</td>\n",
       "      <td>[i, heard, betty, reid, soskin, is, retiring, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1510050583197237252</td>\n",
       "      <td>2022-04-02 00:24:49+00:00</td>\n",
       "      <td>i'm proud of titus, ashton, thaddeus, jalen, m...</td>\n",
       "      <td>[i, 'm, proud, of, titus, ,, ashton, ,, thadde...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1507085038940262408</td>\n",
       "      <td>2022-03-24 20:00:48+00:00</td>\n",
       "      <td>today @potus announced that the u.s. will be w...</td>\n",
       "      <td>[today, @, potus, announced, that, the, u.s., ...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1506730193712467970</td>\n",
       "      <td>2022-03-23 20:30:46+00:00</td>\n",
       "      <td>as the first woman to serve as america’s top d...</td>\n",
       "      <td>[as, the, first, woman, to, serve, as, america...</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>Openness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1506718741459091464</td>\n",
       "      <td>2022-03-23 19:45:16+00:00</td>\n",
       "      <td>the other day, i called up donnamarie, steve, ...</td>\n",
       "      <td>[the, other, day, ,, i, called, up, donnamarie...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 created_at  \\\n",
       "0  1510286021182771200  2022-04-02 16:00:21+00:00   \n",
       "1  1510050583197237252  2022-04-02 00:24:49+00:00   \n",
       "2  1507085038940262408  2022-03-24 20:00:48+00:00   \n",
       "3  1506730193712467970  2022-03-23 20:30:46+00:00   \n",
       "4  1506718741459091464  2022-03-23 19:45:16+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  i heard betty reid soskin is retiring at 100, ...   \n",
       "1  i'm proud of titus, ashton, thaddeus, jalen, m...   \n",
       "2  today @potus announced that the u.s. will be w...   \n",
       "3  as the first woman to serve as america’s top d...   \n",
       "4  the other day, i called up donnamarie, steve, ...   \n",
       "\n",
       "                                    tokenized_tweets  personality_score  \\\n",
       "0  [i, heard, betty, reid, soskin, is, retiring, ...           0.000000   \n",
       "1  [i, 'm, proud, of, titus, ,, ashton, ,, thadde...           0.000000   \n",
       "2  [today, @, potus, announced, that, the, u.s., ...           0.016393   \n",
       "3  [as, the, first, woman, to, serve, as, america...           0.013699   \n",
       "4  [the, other, day, ,, i, called, up, donnamarie...           0.000000   \n",
       "\n",
       "     Personality  \n",
       "0        Unknown  \n",
       "1        Unknown  \n",
       "2  Agreeableness  \n",
       "3       Openness  \n",
       "4        Unknown  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Personality = ['Openness', 'Agreeableness']\n",
    "clean_data = CleanData(df)\n",
    "clean_data.read_persona_dict(Personality)\n",
    "clean_data.pre_processing_dataframe()\n",
    "clean_data.get_persona_scores()\n",
    "clean_data.df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2b740fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "tweet_example = all_positive_tweets[2277]\n",
    "tweet_example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
