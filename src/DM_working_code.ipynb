{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6908d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vinu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Required Libraries\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "stopwords_english = stopwords.words('english')\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "9dbaba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Dataframe cell \n",
    "\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\vinu1\\\\Personality_perception\\\\data\\\\Tweets\\\\BarackObama_tweets.csv')\n",
    "# df.drop(['Unnamed: 0', 'Index',  \n",
    "#                 'Location', 'Subcategory',\n",
    "#        'Unnamed: 5'], axis=1, inplace=True)\n",
    "# df['text'] = df['text'].str.lower()\n",
    "# df['text']\n",
    "\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "train_pos = all_positive_tweets[:]\n",
    "train_neg = all_negative_tweets[:]\n",
    "train_x = train_pos+train_neg\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "df_train = pd.DataFrame()\n",
    "df_train[\"text\"] = train_x\n",
    "df_train[\"sentiment\"] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b2d9a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    \n",
    "    def __init__(self, df_test,df_train):\n",
    "         self.df_test_cleaned = df_test\n",
    "         self.df_train_cleaned = df_train\n",
    "         self.Openness_list = []\n",
    "         self.Agreeableness_list = []\n",
    "         self.all_positive_tweets = []\n",
    "         self.all_negative_tweets = []\n",
    "         self.stopwords_english = stopwords.words('english')\n",
    "        \n",
    "    def read_persona_dict(self, Personality):\n",
    "        for i in Personality:\n",
    "            path = f\"C:\\\\Users\\\\vinu1\\\\Personality_perception\\\\data\\\\Dictionary\\\\{i}.txt\"\n",
    "            with open(path) as file:\n",
    "                if i == \"Openness\":\n",
    "                   self.Openness_list = [line.rstrip() for line in file]\n",
    "                   self.Openness_list = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in self.Openness_list]\n",
    "                elif i == \"Agreeableness\":\n",
    "                   self.Agreeableness_list = [line.rstrip() for line in file]\n",
    "                   self.Agreeableness_list = [re.sub(r\"[^a-zA-Z0-9]\", \"\", file) for file in self.Agreeableness_list]\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def pre_processing_dataframe(self,df):\n",
    "#         df[\"text\"] = df[\"text\"].str.lower()\n",
    "#         word_token_list = []\n",
    "#         for i in range(len(df.index)):\n",
    "#             word_token = word_tokenize(df[\"text\"][i])\n",
    "#             word_token_list.append(word_token)\n",
    "#         df1 = pd.DataFrame(word_token_list)\n",
    "#         df1['tokenized_tweets']=df1.apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "#         df_token = df1[['tokenized_tweets']]\n",
    "#         df = pd.concat([df.reset_index(drop=True), df_token], axis=1)\n",
    "        \n",
    "        stopwords_english = stopwords.words('english')\n",
    "        punctuations = string.punctuation\n",
    "        stemmer = PorterStemmer()\n",
    "        tokenizer = TweetTokenizer(preserve_case = False, strip_handles=True, reduce_len = True)\n",
    "        #### Removing the unwanted things in the tweets\n",
    "        df[\"text\"]=df[\"text\"].apply(lambda x: re.sub(r'RT[\\s]+','', str(x)))\n",
    "        df['text']=df['text'].apply(lambda x: re.sub(r\"http\\S+\",'', str(x)))\n",
    "        df['text']=df['text'].apply(lambda x: re.sub(r'#', '', str(x)))\n",
    "        df['tokenized_tweets']=df['text'].apply(lambda x: word_tokenize(x))\n",
    "        \n",
    "        df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [word.lower() for word in x if (word not in stopwords_english and word not in punctuations)])\n",
    "\n",
    "\n",
    "        \n",
    "    def pre_process(self, x):\n",
    "        if x == \"train\":\n",
    "            self.pre_processing_dataframe(self.df_train_cleaned)\n",
    "        elif x == \"test\":\n",
    "            self.pre_processing_dataframe(self.df_test_cleaned)\n",
    "        \n",
    "    def get_persona_scores(self):\n",
    "        max_list = []\n",
    "        persona_list = []\n",
    "        open_count, agree_count = 0 , 0\n",
    "        open_ratio, agree_ratio = 0 , 0\n",
    "\n",
    "        for i in range(len(self.df_test_cleaned.index)):\n",
    "            max_score = 0\n",
    "            open_count, agree_count = 0 , 0\n",
    "            open_ratio, agree_ratio = 0 , 0\n",
    "            for j in range(len(self.df_test_cleaned[\"tokenized_tweets\"][i])):\n",
    "\n",
    "                if (self.df_test_cleaned[\"tokenized_tweets\"][i][j] in self.Openness_list):\n",
    "                    open_count += 1\n",
    "\n",
    "                    open_ratio = open_count/len(self.Openness_list)\n",
    "                if (self.df_test_cleaned[\"tokenized_tweets\"][i][j] in self.Agreeableness_list):\n",
    "                    agree_count +=1\n",
    "                    agree_ratio = agree_count/len(self.Agreeableness_list)\n",
    "            max_score = max(open_ratio,agree_ratio)\n",
    "            max_list.append(max_score)\n",
    "            \n",
    "\n",
    "            if max_score == 0:\n",
    "                x = \"Unknown\"\n",
    "            elif max_score == open_ratio:\n",
    "                x = \"Openness\"\n",
    "            elif max_score == agree_ratio:\n",
    "                x = \"Agreeableness\"\n",
    "\n",
    "            persona_list.append(x)\n",
    "\n",
    "\n",
    "        self.df_test_cleaned[\"personality_score\"] = max_list\n",
    "        self.df_test_cleaned[\"Personality\"] = persona_list\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e695cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_predict_data(CleanData):\n",
    "   def create_frequency(self):\n",
    "        freq_d = {}\n",
    "        for i in range(len(self.df_train_cleaned.index)):\n",
    "            for word in self.df_train_cleaned[\"tokenized_tweets\"][i]:\n",
    "                pair = (word, self.df_train_cleaned[\"sentiment\"][i])\n",
    "                if pair in freq_d:\n",
    "                    freq_d[pair] += 1\n",
    "                else:\n",
    "                    freq_d[pair] = freq_d.get(pair, 1)\n",
    "    \n",
    "        return freq_d\n",
    "    \n",
    "   def train_naive_bayes(self,freqs, train_x, train_y):\n",
    "        loglikelihood = {}\n",
    "        logprior = 0\n",
    "\n",
    "        unique_words = set([pair[0] for pair in freqs.keys()])\n",
    "\n",
    "        V = len(unique_words)\n",
    "\n",
    "        N_pos = N_neg = 0\n",
    "        for pair in freqs.keys():\n",
    "            if pair[1]>0:\n",
    "                N_pos+=freqs[(pair)]\n",
    "\n",
    "            else:\n",
    "                N_neg += freqs[(pair)]\n",
    "        D = train_y.shape[0]\n",
    "\n",
    "        D_pos = sum(train_y)\n",
    "\n",
    "        D_neg = D-sum(train_y)\n",
    "\n",
    "        logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "        for word in unique_words:\n",
    "            freq_pos = freqs.get((word, 1),0)\n",
    "            freq_neg = freqs.get((word, 0), 0)\n",
    "            p_w_pos = (freq_pos+1)/(N_pos+V)\n",
    "            p_w_neg = (freq_neg+1)/(N_neg+V)\n",
    "            loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "        return logprior, loglikelihood\n",
    "    \n",
    "   def naive_bayes_predict(self,logprior,loglikelihood):\n",
    "       sentiment_score = []\n",
    "       for i in range(len(self.df_test_cleaned.index)):\n",
    "               p = 0\n",
    "               p+=logprior\n",
    "               for word in self.df_test_cleaned[\"tokenized_tweets\"][i]:\n",
    "                 if word in loglikelihood:\n",
    "                   p+=loglikelihood[word]\n",
    "               sentiment_score.append(p)\n",
    "       self.df_test_cleaned[\"sentiment_score\"] = sentiment_score\n",
    "    \n",
    "   def sentiment_persona(self):\n",
    "      sentiment_persona = []\n",
    "      for i in range(len(self.df_test_cleaned.index)):\n",
    "                score  = self.df_test_cleaned[\"sentiment_score\"][i]\n",
    "                if (-0.5 < score < 0.5):\n",
    "                    x  = \"Neutral\"\n",
    "                elif (score < -0.5):\n",
    "                    x = \"Negative\"\n",
    "                elif (score > 0.5):\n",
    "                    x = \"Positive\"\n",
    "                sentiment_persona.append(x)\n",
    "      self.df_test_cleaned[\"sentiment_persona\"] = sentiment_persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "935f96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Personality = ['Openness', 'Agreeableness']\n",
    "# clean_data = CleanData(df)\n",
    "train_data = Training_predict_data(df_test, df_train)\n",
    "train_data.read_persona_dict(Personality)\n",
    "train_data.pre_process(\"test\")\n",
    "train_data.pre_process(\"train\")\n",
    "train_data.get_persona_scores()\n",
    "freq_d=train_data.create_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "42683bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_data.train_naive_bayes(freq_d, train_x, train_y)\n",
    "\n",
    "train_data.naive_bayes_predict(logprior,loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "df5f3026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>personality_score</th>\n",
       "      <th>Personality</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1510286021182771200</td>\n",
       "      <td>2022-04-02 16:00:21+00:00</td>\n",
       "      <td>I heard Betty Reid Soskin is retiring at 100, ...</td>\n",
       "      <td>[i, heard, betty, reid, soskin, retiring, 100,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.658966</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1510050583197237252</td>\n",
       "      <td>2022-04-02 00:24:49+00:00</td>\n",
       "      <td>I'm proud of Titus, Ashton, Thaddeus, Jalen, M...</td>\n",
       "      <td>[i, 'm, proud, titus, ashton, thaddeus, jalen,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-1.700571</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1507085038940262408</td>\n",
       "      <td>2022-03-24 20:00:48+00:00</td>\n",
       "      <td>Today @POTUS announced that the U.S. will be w...</td>\n",
       "      <td>[today, potus, announced, u.s., welcoming, 100...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>0.630128</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1506730193712467970</td>\n",
       "      <td>2022-03-23 20:30:46+00:00</td>\n",
       "      <td>As the first woman to serve as America’s top d...</td>\n",
       "      <td>[as, first, woman, serve, america, ’, top, dip...</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>Openness</td>\n",
       "      <td>-0.451976</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1506718741459091464</td>\n",
       "      <td>2022-03-23 19:45:16+00:00</td>\n",
       "      <td>The other day, I called up DonnaMarie, Steve, ...</td>\n",
       "      <td>[the, day, i, called, donnamarie, steve, amy, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.644516</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>576151284757073920</td>\n",
       "      <td>2015-03-12 22:42:25+00:00</td>\n",
       "      <td>@JimmyKimmelLive: TBT Just two dudes sharing a...</td>\n",
       "      <td>[jimmykimmellive, tbt, just, two, dudes, shari...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.197737</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>576133874511519744</td>\n",
       "      <td>2015-03-12 21:33:14+00:00</td>\n",
       "      <td>We've already tripled wind energy in America, ...</td>\n",
       "      <td>[we, 've, already, tripled, wind, energy, amer...</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>Openness</td>\n",
       "      <td>-1.763139</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>576104761679708160</td>\n",
       "      <td>2015-03-12 19:37:33+00:00</td>\n",
       "      <td>Who will take home the title of ChampionDenier...</td>\n",
       "      <td>[who, take, home, title, championdenier, vote]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.105253</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>575764044138708993</td>\n",
       "      <td>2015-03-11 21:03:39+00:00</td>\n",
       "      <td>@FLOTUS: If you submit a video on your high sc...</td>\n",
       "      <td>[flotus, if, submit, video, high, school, fafs...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>1.467033</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>575457817827500035</td>\n",
       "      <td>2015-03-11 00:46:49+00:00</td>\n",
       "      <td>ICYMI: Nearly 11.7 million Americans enrolled ...</td>\n",
       "      <td>[icymi, nearly, 11.7, million, americans, enro...</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>Openness</td>\n",
       "      <td>1.394930</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                 created_at  \\\n",
       "0     1510286021182771200  2022-04-02 16:00:21+00:00   \n",
       "1     1510050583197237252  2022-04-02 00:24:49+00:00   \n",
       "2     1507085038940262408  2022-03-24 20:00:48+00:00   \n",
       "3     1506730193712467970  2022-03-23 20:30:46+00:00   \n",
       "4     1506718741459091464  2022-03-23 19:45:16+00:00   \n",
       "...                   ...                        ...   \n",
       "3245   576151284757073920  2015-03-12 22:42:25+00:00   \n",
       "3246   576133874511519744  2015-03-12 21:33:14+00:00   \n",
       "3247   576104761679708160  2015-03-12 19:37:33+00:00   \n",
       "3248   575764044138708993  2015-03-11 21:03:39+00:00   \n",
       "3249   575457817827500035  2015-03-11 00:46:49+00:00   \n",
       "\n",
       "                                                   text  \\\n",
       "0     I heard Betty Reid Soskin is retiring at 100, ...   \n",
       "1     I'm proud of Titus, Ashton, Thaddeus, Jalen, M...   \n",
       "2     Today @POTUS announced that the U.S. will be w...   \n",
       "3     As the first woman to serve as America’s top d...   \n",
       "4     The other day, I called up DonnaMarie, Steve, ...   \n",
       "...                                                 ...   \n",
       "3245  @JimmyKimmelLive: TBT Just two dudes sharing a...   \n",
       "3246  We've already tripled wind energy in America, ...   \n",
       "3247  Who will take home the title of ChampionDenier...   \n",
       "3248  @FLOTUS: If you submit a video on your high sc...   \n",
       "3249  ICYMI: Nearly 11.7 million Americans enrolled ...   \n",
       "\n",
       "                                       tokenized_tweets  personality_score  \\\n",
       "0     [i, heard, betty, reid, soskin, retiring, 100,...           0.000000   \n",
       "1     [i, 'm, proud, titus, ashton, thaddeus, jalen,...           0.000000   \n",
       "2     [today, potus, announced, u.s., welcoming, 100...           0.016393   \n",
       "3     [as, first, woman, serve, america, ’, top, dip...           0.013699   \n",
       "4     [the, day, i, called, donnamarie, steve, amy, ...           0.000000   \n",
       "...                                                 ...                ...   \n",
       "3245  [jimmykimmellive, tbt, just, two, dudes, shari...           0.000000   \n",
       "3246  [we, 've, already, tripled, wind, energy, amer...           0.013699   \n",
       "3247     [who, take, home, title, championdenier, vote]           0.000000   \n",
       "3248  [flotus, if, submit, video, high, school, fafs...           0.016393   \n",
       "3249  [icymi, nearly, 11.7, million, americans, enro...           0.013699   \n",
       "\n",
       "        Personality  sentiment_score sentiment_persona  \n",
       "0           Unknown        -0.658966          Negative  \n",
       "1           Unknown        -1.700571          Negative  \n",
       "2     Agreeableness         0.630128          Positive  \n",
       "3          Openness        -0.451976           Neutral  \n",
       "4           Unknown         2.644516          Positive  \n",
       "...             ...              ...               ...  \n",
       "3245        Unknown         1.197737          Positive  \n",
       "3246       Openness        -1.763139          Negative  \n",
       "3247        Unknown         1.105253          Positive  \n",
       "3248  Agreeableness         1.467033          Positive  \n",
       "3249       Openness         1.394930          Positive  \n",
       "\n",
       "[3250 rows x 8 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sentiment_persona()\n",
    "train_data.df_test_cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
